{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3Ew1pEmu05z"
      },
      "source": [
        "# DSA - Deep Learning [5] - Reinforcement learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51-HV2WWMG8A",
        "outputId": "6535ac24-b56e-463e-ed6b-2356b95a3aee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flappy-bird-gymnasium in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (from flappy-bird-gymnasium) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from flappy-bird-gymnasium) (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from flappy-bird-gymnasium) (3.8.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium->flappy-bird-gymnasium) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium->flappy-bird-gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium->flappy-bird-gymnasium) (0.0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flappy-bird-gymnasium) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->flappy-bird-gymnasium) (1.16.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-opengl is already the newest version (3.1.5+dfsg-1).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.10/dist-packages (3.0)\n",
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install flappy-bird-gymnasium pygame\n",
        "!apt-get install -y xvfb python3-opengl ffmpeg\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TCYjQVtsMHbO"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pygame\n",
        "import imageio\n",
        "from IPython.display import display, Image\n",
        "from PIL import Image as PILImage  # Importing PIL for image manipulation\n",
        "from flappy_bird_gymnasium.envs.flappy_bird_env import FlappyBirdEnv\n",
        "\n",
        "# Set environment variables for rendering and audio in Colab\n",
        "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
        "os.environ[\"SDL_AUDIODRIVER\"] = \"dummy\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Mx7sUp9JMIqp"
      },
      "outputs": [],
      "source": [
        "class CustomFlappyBirdEnv(FlappyBirdEnv):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initialize pygame and enforce dummy display\n",
        "        pygame.init()\n",
        "        if not pygame.display.get_init():\n",
        "            pygame.display.init()\n",
        "        pygame.display.set_mode((1, 1))  # Enforce dummy video mode\n",
        "\n",
        "        # Initialize pygame mixer for audio\n",
        "        if not pygame.mixer.get_init():\n",
        "            pygame.mixer.init()\n",
        "\n",
        "        # Initialize game surface\n",
        "        self._surface = pygame.Surface((288, 512))  # Game surface dimensions\n",
        "\n",
        "        # Initialize display surface (required for FlappyBirdEnv rendering)\n",
        "        self._display = pygame.display.set_mode((288, 512))  # Create display window of appropriate size\n",
        "\n",
        "        # Initialize the FPS clock for controlling the frame rate\n",
        "        self._fps_clock = pygame.time.Clock()  # Initialize the FPS clock\n",
        "\n",
        "        # Initialize image assets\n",
        "        self._images = {}\n",
        "\n",
        "        # Load images required for the game\n",
        "        self._images[\"background\"] = self._load_image(\"background-day.png\")\n",
        "        self._images[\"pipe\"] = [\n",
        "            self._load_image(\"pipe-green.png\"),  # Top pipe\n",
        "            pygame.transform.flip(self._load_image(\"pipe-green.png\"), False, True)  # Bottom pipe (flipped)\n",
        "        ]\n",
        "        self._images[\"base\"] = self._load_image(\"base.png\")\n",
        "        self._images[\"player\"] = [\n",
        "            self._load_image(\"yellowbird-upflap.png\"),\n",
        "            self._load_image(\"yellowbird-midflap.png\"),\n",
        "            self._load_image(\"yellowbird-downflap.png\"),\n",
        "        ]\n",
        "        self._images[\"numbers\"] = {\n",
        "            i: self._load_image(f\"{i}.png\") for i in range(10)  # Load images for digits 0-9\n",
        "        }\n",
        "\n",
        "        # Load audio assets if needed\n",
        "        self._audio = {\n",
        "            \"wing\": self._load_audio(\"wing.wav\"),\n",
        "            \"point\": self._load_audio(\"point.wav\"),\n",
        "            \"hit\": self._load_audio(\"hit.wav\"),\n",
        "            \"die\": self._load_audio(\"die.wav\"),\n",
        "        }\n",
        "\n",
        "        # Additional attributes required by the parent class\n",
        "        self._score = 0\n",
        "        self._player_index = 0\n",
        "        self._base_shift = self._images[\"base\"].get_width() - self._surface.get_width()\n",
        "        self._pipes = []\n",
        "        self._player_y = 256\n",
        "        self._player_velocity_y = 0\n",
        "        self._gravity = 1\n",
        "        self._pipe_gap = 100\n",
        "\n",
        "    def _load_image(self, filename):\n",
        "        \"\"\"\n",
        "        Load an image from the assets directory.\n",
        "        Args:\n",
        "            filename: Name of the image file.\n",
        "        Returns:\n",
        "            Loaded pygame image.\n",
        "        \"\"\"\n",
        "        assets_path = \"/usr/local/lib/python3.10/dist-packages/flappy_bird_gymnasium/assets/sprites\"\n",
        "        filepath = os.path.join(assets_path, filename)\n",
        "        return pygame.image.load(filepath).convert_alpha()\n",
        "\n",
        "    def _load_audio(self, filename):\n",
        "        \"\"\"\n",
        "        Load an audio file from the assets directory.\n",
        "        Args:\n",
        "            filename: Name of the audio file.\n",
        "        Returns:\n",
        "            Loaded pygame audio sound.\n",
        "        \"\"\"\n",
        "        assets_path = \"/usr/local/lib/python3.10/dist-packages/flappy_bird_gymnasium/assets/audio\"\n",
        "        filepath = os.path.join(assets_path, filename)\n",
        "        return pygame.mixer.Sound(filepath)\n",
        "\n",
        "    def render(self):\n",
        "        \"\"\"\n",
        "        Render the game screen to the display and capture the frame for Colab visualization.\n",
        "        \"\"\"\n",
        "        super().render()  # Call the parent class's render method\n",
        "\n",
        "        # Capture the screen as an array\n",
        "        frame = pygame.surfarray.array3d(pygame.display.get_surface())\n",
        "        self.frames.append(frame)  # Save the frame for GIF creation\n",
        "\n",
        "        # Control frame rate\n",
        "        self._fps_clock.tick(self.metadata[\"render_fps\"])\n",
        "\n",
        "    def create_gif(self, gif_name=\"flappy_bird_game.gif\"):\n",
        "        \"\"\"\n",
        "        Create and display a GIF from the captured frames.\n",
        "        \"\"\"\n",
        "        flipped_frames = []\n",
        "        for frame in self.frames:\n",
        "            pil_frame = PILImage.fromarray(frame)\n",
        "            flipped_frame = pil_frame.rotate(270, expand=True)  # Rotate 270 degrees\n",
        "            flipped_frames.append(flipped_frame)\n",
        "\n",
        "        # Save and display the GIF\n",
        "        flipped_gif_name = gif_name.replace(\".gif\", \"_flipped.gif\")\n",
        "        imageio.mimsave(flipped_gif_name, flipped_frames, duration=1 / self.metadata[\"render_fps\"])\n",
        "        display(Image(flipped_gif_name))\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reset the environment and clear the stored frames.\n",
        "        \"\"\"\n",
        "        self.frames = []  # Clear captured frames\n",
        "        return super().reset()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the initializing function --> refer to DQN Learning slide\n",
        "class DQN(torch.nn.Module):\n",
        "  def __init__(self, state_size, action_size):\n",
        "      super(DQN, self).__init__()\n",
        "      self.fc1 = torch.nn.Linear(state_size, 128)\n",
        "      self.fc2 = torch.nn.Linear(128, 128)\n",
        "      self.fc3 = torch.nn.Linear(128, action_size)\n",
        "\n",
        "  def forward(self, x):  # forward propogation function passes data into neural network layers to produce an input\n",
        "      x = torch.relu(self.fc1(x))\n",
        "      x = torch.relu(self.fc2(x))\n",
        "      return self.fc3(x)"
      ],
      "metadata": {
        "id": "XbYJeF3RQWRR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_state(state): # collect every single frame of the game\n",
        "  if isinstance(state, tuple):\n",
        "    observation = state[0] # state is in a cuboid format (type of data format) and convert into an array\n",
        "  else:\n",
        "    observation = state\n",
        "\n",
        "  observation = np.array(observation, dtype=np.float32) # where the position of the pipes, players are etc.\n",
        "\n",
        "  if observation.max() > 1.0:\n",
        "    observation = observation / 255.0  # 255.0 is the normalising algorithm (for data points to have the same scale) for efficiency purposes\n",
        "\n",
        "  return observation.flatten() # becomes a 1D array so that it's easier to be used for other data further on. less complex for calculations also."
      ],
      "metadata": {
        "id": "h4gE0REXTVTd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making a training policy for the agent, so that don't have to train the agent every time you open the game\n",
        "def train_dqn(env, num_episodes, model_save_path=\"flappy_bird_dqn_final.pth\", checkpoint_interval=100):\n",
        "    \"\"\"\n",
        "    Train the DQN model on the environment.\n",
        "    Args:\n",
        "        env: The Flappy Bird environment.\n",
        "        num_episodes: Number of training episodes.\n",
        "        model_save_path: File path to save the final trained model.\n",
        "        checkpoint_interval: Number of episodes between saving model checkpoints.\n",
        "    Returns:\n",
        "        Trained model.\n",
        "    \"\"\"\n",
        "    # Determine state and action sizes dynamically\n",
        "    state = preprocess_state(env.reset())\n",
        "    state_size = state.shape[0]\n",
        "    action_size = env.action_space.n\n",
        "\n",
        "    # Initialize the DQN model\n",
        "    model = DQN(state_size, action_size)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "    # Replay buffer for storing experiences\n",
        "    replay_buffer = []\n",
        "    max_buffer_size = 1000\n",
        "\n",
        "    # Hyperparameters\n",
        "    gamma = 0.99  # Discount factor\n",
        "    epsilon = 1.0  # Initial exploration rate\n",
        "    epsilon_min = 0.01  # Minimum exploration rate\n",
        "    epsilon_decay = 0.995  # Decay factor for exploration rate\n",
        "\n",
        "    # Metrics\n",
        "    rewards_per_episode = []  # Track rewards per episode\n",
        "    steps_per_episode = []  # Track steps per episode\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        state = preprocess_state(env.reset())  # Preprocess the initial state\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "        steps = 0\n",
        "\n",
        "        while not done:\n",
        "            # Convert state to tensor\n",
        "            state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "\n",
        "            # Select an action (epsilon-greedy policy)\n",
        "            if random.random() < epsilon:  # Explore\n",
        "                action = random.choice(range(action_size))\n",
        "            else:  # Exploit the learned policy\n",
        "                with torch.no_grad():\n",
        "                    action = torch.argmax(model(state_tensor)).item()\n",
        "\n",
        "            # Perform the action in the environment\n",
        "            next_state, reward, done, _, _ = env.step(action)\n",
        "            next_state = preprocess_state(next_state)  # Preprocess the next state\n",
        "            total_reward += reward\n",
        "            steps += 1\n",
        "\n",
        "            # Store the experience in the replay buffer\n",
        "            replay_buffer.append((state, action, reward, next_state, done))\n",
        "            if len(replay_buffer) > max_buffer_size:\n",
        "                replay_buffer.pop(0)  # Remove the oldest experience\n",
        "\n",
        "            # Sample a random batch from the replay buffer for training\n",
        "            if len(replay_buffer) >= 32:\n",
        "                batch = random.sample(replay_buffer, 32)\n",
        "                states, actions, rewards, next_states, dones = zip(*batch)\n",
        "\n",
        "                # Convert batch to tensors\n",
        "                states_tensor = torch.FloatTensor(states)\n",
        "                actions_tensor = torch.LongTensor(actions).unsqueeze(1)\n",
        "                rewards_tensor = torch.FloatTensor(rewards).unsqueeze(1)\n",
        "                next_states_tensor = torch.FloatTensor(next_states)\n",
        "                dones_tensor = torch.FloatTensor(dones).unsqueeze(1)\n",
        "\n",
        "                # Compute Q values for the current states\n",
        "                q_values = model(states_tensor).gather(1, actions_tensor)\n",
        "\n",
        "                # Compute target Q values\n",
        "                with torch.no_grad():\n",
        "                    next_q_values = model(next_states_tensor).max(1, keepdim=True)[0]\n",
        "                    targets = rewards_tensor + gamma * next_q_values * (1 - dones_tensor)\n",
        "\n",
        "                # Compute loss\n",
        "                loss = loss_fn(q_values, targets)\n",
        "\n",
        "                # Backpropagation\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            # Move to the next state\n",
        "            state = next_state\n",
        "\n",
        "        # Decay exploration rate\n",
        "        if epsilon > epsilon_min:\n",
        "            epsilon *= epsilon_decay\n",
        "\n",
        "        # Track metrics\n",
        "        rewards_per_episode.append(total_reward)\n",
        "        steps_per_episode.append(steps)"
      ],
      "metadata": {
        "id": "h-iAbHDEUTPn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(env, model_path=\"flappy_bird_dqn_final.pth\"):\n",
        "    \"\"\"\n",
        "    Load the trained RL model.\n",
        "    Args:\n",
        "        env: The Flappy Bird environment.\n",
        "        model_path: Path to the saved model file.\n",
        "    Returns:\n",
        "        Loaded model.\n",
        "    \"\"\"\n",
        "    # Preprocess the initial state to determine its size\n",
        "    state = preprocess_state(env.reset())\n",
        "    state_size = state.shape[0]\n",
        "    action_size = env.action_space.n\n",
        "\n",
        "    # Initialize the DQN model with the correct dimensions\n",
        "    model = DQN(state_size, action_size)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    return model"
      ],
      "metadata": {
        "id": "cSTXHRpsepD2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# each step is a frame in the game\n",
        "def test_rl_agent_playing(env, model, step_limit = 500):\n",
        "  state = preprocess_state(env.reset())\n",
        "  for step in range(step_limit):\n",
        "    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      action = torch.argmax(model(state_tensor)).item()\n",
        "\n",
        "      next_state, reward, done, _. _ = env.step(action)\n",
        "      next_state = preprocess_state(next_state)\n",
        "\n",
        "      env.render()\n",
        "\n",
        "      if done:\n",
        "        break # ends the game\n",
        "\n",
        "      state = next_state # if game hasn't ended, enters the next stafe\n",
        "\n",
        "    env.create_gif()"
      ],
      "metadata": {
        "id": "ZWsmXeQ8e8GJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = CustomFlappyBirdEnv()"
      ],
      "metadata": {
        "id": "WmNdVZvegTvq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_dqn(env, num_episodes = 500, model_save_path = \"flappy_bird_dqn_final.pth\", checkpoint_interval = 1000)"
      ],
      "metadata": {
        "id": "rFveE1cFg9_E"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(env, \"flappy_bird_dqn_final.pth\")\n",
        "\n",
        "test_rl_agent_playing(env, model)"
      ],
      "metadata": {
        "id": "rgFmh8gLhTa4",
        "outputId": "2d64bbb2-df72-4279-9a6d-b5a7b9c6e2ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-b18a0f46fe67>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'flappy_bird_dqn_final.pth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-58f49145ca88>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"flappy_bird_dqn_final.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_rl_agent_playing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-b18a0f46fe67>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(env, model_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Initialize the DQN model with the correct dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Set the model to evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1317\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1319\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'flappy_bird_dqn_final.pth'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}